{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_query = \"I'm surprised by the outcome.\"\n",
    "pos_query = \"I feel happy and content\"\n",
    "neg_query = \"I feel sad and down.\"\n",
    "space = Stadium(model_card=model_card)\n",
    "space.update(input_query, pos_query, neg_query)\n",
    "\n",
    "unseen_query = \"I am quite upset....\"\n",
    "space.scope(unseen=unseen_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829eb48a-db76-4c7f-84a6-77250317f906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/garfield/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/garfield/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbourhood Shape input for inputs: torch.Size([1, 768]), hit: torch.Size([1, 768]), kill: torch.Size([1, 768])\n",
      "Final Loss: 0.5181572437286377\t Hit loss: 0.6083676815032959\t Kill loss: 0.5902104377746582\n",
      "Statistics for inputs:\n",
      "Mean: -0.00019438983872532845\n",
      "Min: -0.07776722311973572\n",
      "Max: 0.09080427139997482\n",
      "Std Dev: 0.030234744772315025\n",
      "------------------------------\n",
      "Statistics for green:\n",
      "Mean: -0.002591716591268778\n",
      "Min: -0.08802705258131027\n",
      "Max: 0.07704823464155197\n",
      "Std Dev: 0.02962050586938858\n",
      "------------------------------\n",
      "Statistics for red:\n",
      "Mean: -0.0007843842031434178\n",
      "Min: -0.08093810081481934\n",
      "Max: 0.08672217279672623\n",
      "Std Dev: 0.029796775430440903\n",
      "------------------------------\n",
      "Neighbourhood Shape input for inputs: torch.Size([1, 768]), hit: torch.Size([1, 768]), kill: torch.Size([1, 768])\n",
      "Final Loss: 0.09746521711349487\t Hit loss: 0.5004544854164124\t Kill loss: 0.9029892683029175\n",
      "Statistics for inputs:\n",
      "Mean: -0.0013404383789747953\n",
      "Min: -0.08037427812814713\n",
      "Max: 0.08383028209209442\n",
      "Std Dev: 0.03164714202284813\n",
      "------------------------------\n",
      "Statistics for green:\n",
      "Mean: -0.0015747783472761512\n",
      "Min: -0.0762777104973793\n",
      "Max: 0.06686628609895706\n",
      "Std Dev: 0.027508312836289406\n",
      "------------------------------\n",
      "Statistics for red:\n",
      "Mean: -0.00031391350785270333\n",
      "Min: -0.0936041995882988\n",
      "Max: 0.09947362542152405\n",
      "Std Dev: 0.035014256834983826\n",
      "------------------------------\n",
      "Neighbourhood Shape input for inputs: torch.Size([1, 768]), hit: torch.Size([1, 768]), kill: torch.Size([1, 768])\n",
      "Final Loss: 0.0\t Hit loss: 0.4954240918159485\t Kill loss: 1.213076114654541\n",
      "Statistics for inputs:\n",
      "Mean: -0.002135060727596283\n",
      "Min: -0.08022274076938629\n",
      "Max: 0.08615756779909134\n",
      "Std Dev: 0.033980075269937515\n",
      "------------------------------\n",
      "Statistics for green:\n",
      "Mean: -0.0010163916740566492\n",
      "Min: -0.07310503721237183\n",
      "Max: 0.06773195415735245\n",
      "Std Dev: 0.02714630402624607\n",
      "------------------------------\n",
      "Statistics for red:\n",
      "Mean: 0.00022021611221134663\n",
      "Min: -0.10467516630887985\n",
      "Max: 0.11075521260499954\n",
      "Std Dev: 0.04145575314760208\n",
      "------------------------------\n",
      "Training steps stopped after 2 epochs\n",
      "\n",
      "\n",
      "Testing with unseen data query . . .\n",
      "Statistics for test:\n",
      "Mean: 0.00027017382672056556\n",
      "Min: -0.07363817095756531\n",
      "Max: 0.08523426949977875\n",
      "Std Dev: 0.028676949441432953\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO:\n",
    "# - add a check point to store the last trained inputs' embeddings\n",
    "# - add a path to save Neighbourhood\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "from functools import wraps\n",
    "from sentence_transformers import SentenceTransformer \n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "INPUT_DIM = 768 \n",
    "HIDDEN_DIM = 512\n",
    "OUTPUT_DIM = 1\n",
    "MAX_ITER = 10\n",
    "threshold = 1.0\n",
    "model_card = \"all-mpnet-base-v2\"\n",
    "\n",
    "class galaxy:\n",
    "    @staticmethod\n",
    "    def _monitor(result: torch.tensor, data_name: str = None):\n",
    "        data_name = data_name if data_name is not None else \"test\"\n",
    "        print(f\"Statistics for {data_name}:\")\n",
    "        print(f\"Mean: {result.mean().item()}\")\n",
    "        print(f\"Min: {result.min().item()}\")\n",
    "        print(f\"Max: {result.max().item()}\")\n",
    "        print(f\"Std Dev: {result.std().item()}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    @staticmethod\n",
    "    def monitor(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(self, inputs: torch.tensor, hit_list: torch.tensor, kill_list: torch.tensor):\n",
    "            print(f\"Neighbourhood Shape input for inputs: {inputs.shape}, hit: {hit_list.shape}, kill: {kill_list.shape}\")\n",
    "            inputs, green, red, red_loss = func(self, inputs, hit_list, kill_list)\n",
    "            output = {\n",
    "                'inputs': inputs,\n",
    "                'green': green,\n",
    "                'red': red\n",
    "            }\n",
    "            # Print statistics\n",
    "            for data_name, result in output.items():\n",
    "                galaxy._monitor(result, data_name)\n",
    "            \n",
    "            return inputs, green, red, red_loss\n",
    "        return wrapper\n",
    "\n",
    "    @staticmethod\n",
    "    def moonphase(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            # Call the original function\n",
    "            print(\"\\nTesting with unseen data query . . .\")\n",
    "            result = func(self, *args, **kwargs)\n",
    "            galaxy._monitor(result)\n",
    "            return\n",
    "        \n",
    "        return wrapper\n",
    "\n",
    "class LossAndFound(nn.Module):\n",
    "    def __init__(self, alpha: float = 0.5):\n",
    "        super(LossAndFound, self).__init__()\n",
    "        self.beacon = alpha  \n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, wait_list: torch.Tensor, hit_list: torch.Tensor, kill_list: torch.Tensor) -> torch.Tensor:\n",
    "        assert wait_list.shape ==  hit_list.shape and hit_list.shape == kill_list.shape, f\"Expected all inputs to be of the same shape: {wait_list.shape}, {hit_list.shape} and {kill_list.shape}\"\n",
    "        \n",
    "        wait_list, hit_list, kill_list = wait_list.squeeze(0), hit_list.squeeze(0), kill_list.squeeze(0)\n",
    "        hit_loss = torch.norm((wait_list - hit_list), p=2, dim=0)\n",
    "        kill_loss = torch.norm((wait_list - kill_list), p=2, dim=0)\n",
    "        final_loss = torch.max(torch.tensor(0.0, device=hit_loss.device), hit_loss - kill_loss + self.beacon)\n",
    "        print(f\"Final Loss: {final_loss}\\t Hit loss: {hit_loss}\\t Kill loss: {kill_loss}\")\n",
    "        return final_loss, hit_loss, kill_loss\n",
    "    \n",
    "class Neighbourhood(nn.Module):\n",
    "    def __init__(self, input_dim: int = INPUT_DIM, hidden_dim: int = HIDDEN_DIM, output_dim: int = OUTPUT_DIM, loss_fn: nn.Module = LossAndFound):\n",
    "        super(Neighbourhood, self).__init__()\n",
    "        self.ball = nn.Linear(input_dim, hidden_dim, device=device)\n",
    "        # self.grp = nn.Linear(hidden_dim, output_dim, device=device)\n",
    "        self.loss = loss_fn()\n",
    "        self.opt: torch.optim = optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.to(device)\n",
    "\n",
    "    @galaxy.monitor\n",
    "    def forward(self, inputs: torch.tensor, hit_input: torch.tensor = None, kill_input: torch.tensor = None):\n",
    "        assert inputs.size() == torch.Size([1, 768])\n",
    "        if self.train:\n",
    "            assert inputs.size() == hit_input.size() and inputs.size() == kill_input.size(), f\"Input, target and kill input sizes are different: {inputs.size()}, {hit_input.size()}, {kill_input.size()}\"\n",
    "            self.opt.zero_grad()\n",
    "            x = self.ball(inputs).tanh()\n",
    "            pos = self.ball(hit_input).tanh()\n",
    "            neg = self.ball(kill_input).tanh()\n",
    "            loss, _, red_loss = self.loss(x, pos, neg)\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "            return x, pos, neg, red_loss\n",
    "        else:\n",
    "            return self.ball(inputs).tanh()\n",
    "            \n",
    "class Basement(SentenceTransformer):\n",
    "    def __init__(self, model_card: str = \"all-mpnet-base-v2\"):\n",
    "        super().__init__(model_card, device=device)\n",
    "        # self.encode(args, convert_to_tensor=True, device=device)\n",
    "\n",
    "class Stadium:\n",
    "    def __init__(self, model_card: str = model_card, **kwargs: dict):\n",
    "        self.base = Basement(model_card)\n",
    "        self.model = Neighbourhood(**kwargs)\n",
    "\n",
    "    def update(self, *args: tuple, threshold: float = threshold, max_iter: float = MAX_ITER):\n",
    "        assert len(args) == 3, f\"Expected 3 str inputs for inputs, green, and red but received {len(args)}\"\n",
    "        self.model.train()\n",
    "        inputs, green, red = self.base.encode(args, convert_to_tensor=True, device=device)\n",
    "        inputs, green, red = inputs.unsqueeze(0), green.unsqueeze(0), red.unsqueeze(0)\n",
    "\n",
    "        for ep in range(max_iter):\n",
    "            new_emb, green_emb, red_emb, red_loss = self.model(inputs, green, red)\n",
    "            if red_loss >= threshold:\n",
    "                print(f\"Training steps stopped after {ep} epochs\\n\")\n",
    "                return\n",
    "        print(f\"Training steps took full {max_iter} steps\\n\")\n",
    "\n",
    "    @galaxy.moonphase\n",
    "    def scope(self, unseen: str):\n",
    "        self.model.eval()\n",
    "        embedding = self.base.encode([unseen], convert_to_tensor=True, device=device)\n",
    "        with torch.no_grad():\n",
    "            output= self.model.ball(embedding).tanh()\n",
    "        return output \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # import pandas as pd\n",
    "    # initial_data = pd.read_parquet(\"hf://datasets/dair-ai/emotion/unsplit/train-00000-of-00001.parquet\")\n",
    "    input_query = \"I'm surprised by the outcome.\"\n",
    "    pos_query = \"I feel happy and content\"\n",
    "    neg_query = \"I feel sad and down.\"\n",
    "    space = Stadium(model_card=model_card)\n",
    "    space.update(input_query, pos_query, neg_query)\n",
    "\n",
    "    unseen_query = \"I am quite upset....\"\n",
    "    space.scope(unseen=unseen_query)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
